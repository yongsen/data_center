%\documentclass[11pt]{article}
\documentclass[journal,onecolumn,11pt]{IEEEtran}

\usepackage{blindtext}
\usepackage{etoolbox}
\usepackage{graphicx}

\makeatletter
\def\do#1{\patchcmd{#1}{\thepage}{\null}{}{\GenericWarning{}{Could not patch \string#1}}}
\docsvlist{\@oddhead,\@evenhead,\ps@headings,\ps@IEEEtitlepagestyle,\ps@IEEEpeerreviewcoverpagestyle}
\makeatother

\usepackage{cite}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[left=1in,right=1in,top=1in,bottom=0.8in]{geometry}
\usepackage[bookmarks=false,pdfstartview=FitH,colorlinks,citecolor=blue,filecolor=green,linkcolor=blue,urlcolor=blue]{hyperref}
%\usepackage{bookmark}
%\usepackage[bookmarks=false,pdfstartview=FitH,bookmarksopen=true]{hyperref}
\usepackage{url}
\usepackage[caption=false,font=footnotesize]{subfig}
%\usepackage{fixltx2e}
\usepackage{stfloats}
% this is the preamble
% put all of the above code in here
%\usepackage{setspace}
\setlength{\parskip}{0.5em}

%\makeatletter% since there's an at-sign (@) in the command name
%\renewcommand{\@maketitle}{%
%  \begin{center}
%    \parskip\baselineskip% skip a line between paragraphs in the title block
%    \parindent=0pt% don't indent paragraphs in the title block
%    {\bf\@title}\par
%    \textbf{\@author}\par
%    \@date% remove the percent sign at the beginning of this line if you want the date printed
%  \end{center}
%}
%\makeatother% resets the meaning of the at-sign (@)

\title{Report on Data Centers}
\author{\IEEEauthorblockN{Yongsen MA}
%\IEEEauthorblockA{mayongsen@gmail.com, http://yongsen.github.com}
}
%\markboth{I\MakeLowercase{nterview for} P\MakeLowercase{h}D A\MakeLowercase{pplication of} CS,HKU}{Yongsen MA}

\begin{document}

\maketitle% prints the title block
%\onehalfspacing

\section{Motivation}

With the increasing demand of traffic loads and user requirements, it is a great challenge to make data centers agile and energy-efficient. A basic solution is to allow dynamic resource allocation based on flexible data center networks. The recent development of 60GHz wireless technology opens a door for the deployment of flexible data centers. It provides a good choice of adding capacity to data centers with under-provisioning capacity design. However, this will lead to new problems such as topology control and capacity scheduling, apart from the wireless propagation and link adaption in wireless networks. The PHY and MAC standardization of 60GHz networks is still ongoing (WirelessHD and IEEE 802.11ad/WiGig), its application in data centers should be further explored for the specific feature of topology and services.

\begin{figure}[!htp]
\centerline{
    \subfloat[Provisioning for peak load]{
    \includegraphics[width=0.33\textwidth]{capacity.pdf}
    \label{peak}
    }
    \subfloat[Fixed underprovisioning]{
    \includegraphics[width=0.33\textwidth]{capacity1.pdf}
    \label{under}
    }
    \subfloat[Flexible underprovisioning]{
    \includegraphics[width=0.33\textwidth]{capacity2.pdf}
    \label{under_wireless}
    }
}
\caption{Capacity provisioning based on traffic loads}
\label{provisioning}
\end{figure}

Generally, the capacity of data centers is designed for peak loads, as shown in Figure \ref{peak}, but the resources will be wasted during non-peak times \cite{Armbrust:2010:VCC:1721654.1721672}. On the other hand, if the capacity is designed in under-provisioning case as shown in Figure \ref{under}, the peak requirements can not be satisfied, leading to potential revenue sacrifice or over-occupied errors. To address these problems, we can employ flexible capacity and dynamic demand response, i.e., 60GHz wireless linking to add capacity for peak loads and sleeping mechanism to improve performance/cost efficiency, as shown in Figure \ref{under_wireless}.

The wireless-flexible data centers are generally composed of:
\begin{enumerate}
  \item Topology and Addressing:
  \begin{enumerate}
    \item Conflict Graph: Propagation table (wireless), capacity matrix (wired/wireless) and traffic loads table (wired/wireless)
    \item Topology Graph: Physical-specific ID Addresses (PAs), Logical-specific IP Addresses (LAs) and Application-specific IP Addresses (AAs)
        \begin{enumerate}
        \item PAs: providing distance information for 3D Beamforming
        \item LAs: providing topology information for Capacity Adaption
        \item AAs: providing traffic information for Demand Response
        \end{enumerate}
  \end{enumerate}
  \item Routing and Scheduling:
  \begin{enumerate}
    \item 3D Beamforming: adding additional capacity to neighbor ToRs according to PAs
    \item Demand Response: traffic estimation according to AAs
    \item Capacity Adaption: capacity scheduling according to LAs
  \end{enumerate}
\end{enumerate}

\section{Methodology}

The problems of topology control, addressing, routing, and scheduling also exit in traditional data centers, but it brings new challenges when wireless links are introduced. For instance, the topology graph is changing due to wireless links and on-demand response. Also, the capacity matrix and conflict graph of wireless links are closely related to the relative locations of servers, e.g., capacity of 6G for neighbor servers and 1/2G for non-neighbor servers. Furthermore, the measurement and mapping of topology graph, conflict graph and traffic loads is challenging for large scale data centers.

\begin{figure}[!htp]
\centering
\includegraphics[width=0.8\textwidth]{framework.pdf}
\caption{Framework of flexible data centers based on 60GHz wireless networks}
\label{framework}
\end{figure}

Considering the scale of topology (conflict/topology graph and different addresses) and multi-layer scheduling (physical topology, capacity matrix and traffic patterns), we can employ \textbf{Compress Sensing} and \textbf{Logical Addressing} to address these problems.

\textbf{Topology:} multi-layer tree topology such as Fat-tree and VL2 (or cylindrical racks housing pie-shaped servers \cite{Shin:2012:FCW:2396556.2396560}) with ToRs.

\textbf{Addressing:} changing according to topology, PAs and AAs should be mapped to LAs to make 3D beamforming, demand response and capacity scheduling.

\textbf{Scheduling:} when the capacity matrix and traffic demands are mapped to LAs, we can determine the scheduling strategy including 3D beamforming and routing paths.


\subsection{Compress Sensing}

The conflict graph can be classified into the topology graph, since it represents the wireless connections which provide additional 1/2/6G capacity for different ToRs. It is challenging to measure such a large scale topology graph (PAs and AAs) which usually requires all-to-all communications. Since both conflict graph \cite{Halperin:2011:ADC:2018436.2018442} and topology graph \cite{Chen:2010:GAA:1851182.1851190} are sparse, we can utilize Compress Sensing to reduce overhead, just as the famous example that using only 3 out of 10 words can reconstruct the whole account password. In this way, we can use small number of samples to get the topology so that all-to-all communications are not necessary.

The requirements and reasons for Compress Sensing are:
\begin{enumerate}
  \item topology graphs are \textbf{large}, and so comes the requirement to reduce measuring and mapping overhead
  \item wireless propagation and traffic demand have \textbf{dynamic} furthers, so the measurement is challenging
  \item topology graphs are \textbf{sparse}, which is the prior condition for compress sensing
  \item topology graphs only have \textbf{local changes} (errors, on-off or wireless) in real-time operating
\end{enumerate}

If the adjacency matrix of a given topology graph $G=(V,E)$ is $A^{N\times N}$, it can be represented by $N$ vertex $A_i$. Then the estimated matrix $\hat{y}\in \textbf{R}^n$ can be calculated through the measure matrix $\Phi\in \textbf{R}^{n\times N} (n\ll N)$ as follows:
\begin{equation}
 y=\Phi A_i
 \label{estimation}
\end{equation}
If the measured data is recovered through $\hat{A_i}=f(y)=\Psi y=\Psi\Phi A_i$, the estimated results can be obtained by optimization
\begin{equation}
 min \parallel A_i-f(y) \parallel_{l_x}
 \label{recover1}
\end{equation}
\begin{equation}
 s.t.~~~~\Phi A_i = y
 \label{recover2}
\end{equation}
where $l_x (x=0,1,2)$ are the norms of a vector, among which $l_1$ is usually used representing the number of non-zero coordinates. Then $y$ can be easily measured and $A$ can be reconstructed through $y$ if the measure and reconstruct matrix ($\Phi$ and $\Psi$) are suitably designed. Therefore, all-to-all communications are not required which can help to reduce the measurement overhead. The topology graph can be estimated by Compress Sensing due to its large-scale and sparse feature. Furthermore, the propagation table and traffic loads can be measured in this way according to the measurement results in \cite{Halperin:2011:ADC:2018436.2018442} and \cite{Greenberg:2009:VSF:1592568.1592576}.

The topology that should be measured includes:
\begin{itemize}
  \item Propagation table $\rightarrow$ Capacity matrix: the curve is quite certain for high frequency at near distance (do not consider PHY and MAC settings) \cite{Zhou:2012:MMC:2342356.2342440,Halperin:2011:ADC:2018436.2018442}
  \item PAs $\rightarrow$ LAs
  \item Traffic loads $\rightarrow$ Demands: the distribution of traffic loads has location differences across AAs and ToRs \cite{Halperin:2011:ADC:2018436.2018442,Greenberg:2009:VSF:1592568.1592576}
\end{itemize}

Topology changes due to:
\begin{itemize}
  \item Errors: nodes, links, miswiring
  \item wireless linking (links)
  \item Sleeping on-off (nodes)
\end{itemize}

\subsection{Logical Addressing}

Wireless links make data centers flexible, i.e., using topology control and capacity scheduling to make resource allocation responding to traffic patterns and requirements. So the problem is how to allocate wireless links to deal with the problem of demand response when topology graphs are changing. The capacity matrix is composed of wired and wireless links (direct links between neighbor nodes or 3D beamforming for remote nodes), which can be obtained by PAs:
\begin{itemize}
  \item wired 10G
  \item wireless direct 6G
  \item wireless indirect 1/2G
\end{itemize}

Then the PAs (conflict and topology graphs) and demands estimation (AAs) can be mapped to LAs:
\begin{itemize}
  \item PA to LA for 3D Beamforming
  \item AA to LA for Traffic estimation
\end{itemize}

When the topology graph and traffic demands are mapped to LAs, the capacity scheduling can be made responding to dynamic traffic loads. First, we can get the whole capacity matrix according to propagation table and topology graph. Second, greedy choice of flyways can be made according to capacity matrix an traffic demands. Finally, we can make wireless linking by direct or indirect beamforming if necessary, and make routing and scheduling further.

\section{Literature Review}

Data Center Networks:
\begin{itemize}
  \item Static-electrical:
  \begin{itemize}
    \item Server-centric:
    \begin{itemize}
      \item DCell\cite{Guo:2008:DSF:1402958.1402968}
      \item BCube\cite{Guo:2009:BHP:1592568.1592577}
    \end{itemize}
    \item Multi-level tree:
    \begin{itemize}
      \item Fat-tree\cite{Al-Fares:2008:SCD:1402958.1402967}
      \item VL2\cite{Greenberg:2009:VSF:1592568.1592576}
    \end{itemize}
  \end{itemize}
  \item Flexible:
  \begin{itemize}
    \item Optical:
    \begin{itemize}
      \item c-Through\cite{Wang:2010:CPO:1851182.1851222}
      \item Helios\cite{Farrington:2010:HHE:1851182.1851223}
      \item OSA\cite{chen2012osa}
    \end{itemize}
    \item Wireless:
    \begin{itemize}
      \item Wireless flyways\cite{Halperin:2011:ADC:2018436.2018442}
      \item 3D beamforming\cite{Zhou:2012:MMC:2342356.2342440}
      \item Cylindrical racks with pie-shaped servers \cite{Shin:2012:FCW:2396556.2396560}
    \end{itemize}
  \end{itemize}
\end{itemize}

These papers mainly discussed the issues of:
\begin{itemize}
  \item Topology \cite{Al-Fares:2008:SCD:1402958.1402967,Greenberg:2009:VSF:1592568.1592576,Guo:2008:DSF:1402958.1402968,Guo:2009:BHP:1592568.1592577}
  \item Addressing \cite{Al-Fares:2008:SCD:1402958.1402967,Greenberg:2009:VSF:1592568.1592576}
  \item Mapping \cite{Chen:2010:GAA:1851182.1851190,Greenberg:2009:VSF:1592568.1592576}
  \item Routing \cite{Guo:2008:DSF:1402958.1402968,Guo:2009:BHP:1592568.1592577}
  \item Scheduling \cite{Al-Fares:2008:SCD:1402958.1402967,Halperin:2011:ADC:2018436.2018442}
\end{itemize}

\textbf{"Generic and Automatic Address Configuration for Data Center Networks", SIGCOMM 2010}

Basic Procedures:
\begin{enumerate}
  \item O2 Mapping
  \begin{enumerate}
    \item Candidate selection via SPLD: \textbf{select} candidate with the same SPLD.
    \item Candidate filtering via orbit: \textbf{skip} candidate with the same orbit, then $Decomposition()$.
    \item Selective splitting $Refinement^*()$: \textbf{split} cells that really connect to the including cell.
  \end{enumerate}
  \item Malfunction Detection
  \begin{enumerate}
    \item Anchor pair selection:
    \item Malfunction detection:
  \end{enumerate}
\end{enumerate}

Problems:
\begin{enumerate}
  \item Initial selection of vertex $\nu\in\pi_p^i$
  \item Whether it can be resolved by Compress Sensing?
  \begin{enumerate}
    \item the topology graphs are sparse.
    \item only certain parts are changing in real-time operating (considering certain servers can be turned down for energy-efficiency and demand response).
  \end{enumerate}
\end{enumerate}

\textbf{"OSA: An Optical Switching Architecture for Data Center Networks with Unprecedented Flexibility", NSDI 2012}

Architecture

\textbf{"A Scalable, Commodity Data Center Network Architecture", SIGCOMM 2008}

Topology: k pods, two layers of k/2 switches, each k-port switch connected to k/2 hosts, each remaining k/2 ports connected to k/2 of the k ports in the aggregation layer of the hierarchy. Max $48\cdot \frac{48}{2} \cdot \frac{48}{2}=27648$ hosts for 48-port GigE switches.

Addressing: Pod: 10.pod.switch.1, core: 10.k.j.i, host: 10.pod.switch.ID

\textbf{"DCell: A Scalable and Fault-Tolerant Network Structure for Data Centers", SIGCOMM 2008}

Large-scale, server-centric data centers

Topology:
$n$ servers connected to a mini-switch within $DCell_0$, then $DCell_k$ is recursively generated by $t_{k-1}+1$ $DCell_{k-1}$s. The number of servers scales doubly exponentially as the node degree increases.

Addressing:
a server in $DCell_k$ is denoted by $[a_k,uid_{k-1}]$, where $a_k$ is the $DCell_k$ this server belongs to and $uid_{k-1}$ is the unique ID of the server inside this $DCell_{k-1}$.

Routing: find the connection $(n_1,n_2)$ between $DCell$s, then find the paths of $src$ to $n_1$ and $n_2$ to $dst$. When failures occur, choosing \textit{proxy} to make local-reroute or jump-up (rack failure).

Problems:
\begin{itemize}
  \item the bottleneck link locates in the low-level links and traffics are not balanced
  \item increment expansion requires additional ports which brings extra overhead and complexity
\end{itemize}


\textbf{"BCube: A High Performance, Server-centric Network Architecture for Modular Data Centers", SIGCOMM 2009}

Server-centric modular data centers

Topology:
$BCube_0$ is $n$ servers connecting to an $n$-port switch. $BCube_k$ is constructed from $n$ $BCube_{k-1}$s and $n^k$ $n$-port switches.

Addressing:
servers: $a_ka_{k-1}\cdot\cdot\cdot a_0$ ($a_i\in [0,n-1],i\in [0,k]$); switches: $<l,s_{k-1},s_{k-2}\cdot\cdot\cdot s_0>$, where $l$($0\leq l\leq k$) is the level of the switch.

Routing:


\textbf{"VL2: A Scalable and Flexible Data Center Network", SIGCOMM 2009}

1. Background:
\begin{itemize}
  \item Limited server-to-server capacity: over-subscription ratio increases rapidly
  \item Fragmentation of resources: high turnaround time for reconfiguration
  \item Poor reliability and utilization: multiple paths waste at most 50\% of maximum utilization
\end{itemize}

2. Measurement:
\begin{itemize}
  \item Flow: VLB will perform well on this traffic
  \begin{itemize}
    \item Distribution of flow sizes: majority of flows are small
    \item Number of concurrent flows: 10 concurrent flows at more than 50\% of the time, 80 concurrent flows at least 5\% of the time
  \end{itemize}
  \item Traffic: it is unlikely that other routing strategies will outperform VLB
  \begin{itemize}
    \item Poor summarizability of traffic patterns
    \item Instability of traffic patterns
  \end{itemize}
  \item Failure
\end{itemize}

3. Solution: Virtual Layer 2 Networking
\begin{itemize}
  \item Topology: $D_I$ Int. Switches and $D_A$ Agg. Switches
  \item Addressing: Location-specific IP Addresses and Application-specific IP Addresses
  \item Directory: lookups and updates of AA-to-LA mapping, reactive cache update
\end{itemize}

Problems:
\begin{itemize}
  \item arrive intervals.
  \item application types.
\end{itemize}

Wireless

\textbf{"Mirror Mirror on the Ceiling: Flexible Wireless Links for Data Centers", SIGCOMM 2012}

Wireless Data Center is a new concept which should be explored further. Many issues such as interference, secluding, security, etc. should be standardized. On the other hand, the issues on cost, performance, energy-efficiency, reliability, etc. should be taken into consideration compared with electrical or optical data centers.

%\begin{figure}[!t]
%\centering
%\includegraphics[width=0.4\textwidth]{wirelessdata.pdf}
%\caption{Possible solution: cylindrical racks}
%\label{cylindrical}
%\end{figure}

\begin{enumerate}
  \item electrical
  \item optical
  \item wireless
  \begin{enumerate}
    \item Link Blockage
    \item Radio Interference
  \end{enumerate}
\end{enumerate}

Max concurrent links: Link conflicts (SINR); Greedy scheduling (graph coloring); Assigning radios.

Problems:
\begin{itemize}
  \item Apart from the concurrent links, the efficient throughput should be explored. For instance, although the concurrent links are more with larger ceiling height $h$, it can decrease the throughput according to the curves of RSS (or Data Rate) vs. distance as shown in Figure 5.
\end{itemize}


\textbf{"Augmenting Data Center Networks with Multi-gigabit Wireless Links", SIGCOMM 2011}

"The base wired network is provisioned for the \textbf{average case} and can be oversubscribed. Each ToR switch is equipped withe one or more 60GHz wireless devices." "A central controller monitors DC \textbf{traffic patterns}, and switches the beams of the wireless devices to set up flyways between ToR switches that provide \textbf{added bandwidth} as needed." So it is ideal for \textbf{flexible and energy-efficient} data centers.

Problems:
\begin{itemize}
  \item Conflict graph: for $N$ racks and $K$ antenna orientations, the input table is very \textbf{large} with the size of $(NK)^2$. On the other hand, the propagation conditions are similar, i.e., the table is \textbf{sparse}.
\end{itemize}

to be done

\textbf{"FairCloud: Sharing The Network In Cloud Computing", SIGCOMM 2012}

\textbf{"NetPilot: Automating Datacenter Network Failure Mitigation", SIGCOMM 2012}

\textbf{"Towards Predictable Datacenter Networks", SIGCOMM 2011}

\renewcommand\refname{References}
%\bibliographystyle{alpha}
\bibliographystyle{apalike}
%\IEEEtriggeratref{6}
\bibliography{datacenter}
%\printbibliography
\end{document}
